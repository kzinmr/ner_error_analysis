{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../gsk-ene-1.1-bccwj-json-jumanpp-type/bccwj-ene-jumanpp-type.txt') as f:\n",
    "#     sentences = f.read().split('\\n\\n')\n",
    "#     sentences = [[line.split(' ') for line in sentence.split('\\n') if len(line.split(' '))==5] for sentence in sentences]\n",
    "#     pos = set([line[1] for sentence in sentences for line in sentence])\n",
    "#     bunrui = set([line[2] for sentence in sentences for line in sentence])\n",
    "#     chunk = set([line[3] for sentence in sentences for line in sentence])\n",
    "# pos, bunrui, chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in sorted(bunrui):\n",
    "#     print(f'FinePOSLabelMapper.add(\"{p}\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typomap = {'B-Food': 'Dish',\n",
    "#   'B-Freguency': 'B-Frequency',\n",
    "#   'B-Offense': 'B-Offence',\n",
    "#   'B-Period_time': 'B-Period_Time',\n",
    "#   'B-Position_vocation': 'B-Position_Vocation',\n",
    "#   'I-Food': 'I-Dish',\n",
    "#   'I-Freguency': 'I-Frequency',\n",
    "#   'I-Offense': 'I-Offence',\n",
    "#   'I-Period_time': 'I-Period_Time',\n",
    "#   'I-Position_vocation': 'I-Position_Vocation',\n",
    "#           }\n",
    "\n",
    "# with open('labels_enesub.txt') as f:\n",
    "#     LABELS = {l for l in f.read().split('\\n') if l}\n",
    "# print(len(LABELS))\n",
    "\n",
    "# labels = set()\n",
    "# from collections import Counter\n",
    "# with open('../gsk-ene-1.1-bccwj-json-jumanpp-type/bccwj-ene-jumanpp-type.txt') as f,\\\n",
    "#      open('../gsk-ene-1.1-bccwj-json-jumanpp-type/bccwj-ene-jumanpp-type-sub-fix.txt', 'w') as of:\n",
    "#     sentences = f.read().split('\\n\\n')\n",
    "#     sentences = [[line.split(' ') for line in sentence.split('\\n') if len(line.split(' '))==5] for sentence in sentences]\n",
    "#     for sentence in sentences:\n",
    "#         if len(sentence) > 1:\n",
    "#             if sentence[-1][0] != '。':\n",
    "#                 sentence.append(['。','特殊', '句点', 'O', 'O'])\n",
    "\n",
    "#             for line in sentence:\n",
    "#                 if line[-1] not in LABELS:\n",
    "#                     line[-1] = 'O'\n",
    "#                 if line[-1] in typomap:\n",
    "#                     line[-1] = typomap[line[-1]]\n",
    "#                 labels.add(line[-1])\n",
    "#                 of.write(' '.join(line))\n",
    "#                 of.write('\\n')\n",
    "#             of.write('\\n')\n",
    "#     lasts = Counter([sentence[-1][0] for sentence in sentences])\n",
    "# print(lasts, len(labels), len(LABELS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('labels_enesub.txt') as f:\n",
    "#     LABELS = [l for l in f.read().split('\\n') if l]\n",
    "# print(len(LABELS))\n",
    "# with open('ene-labels-bccwj.txt', 'w') as f:\n",
    "#     for l in LABELS:\n",
    "#         if l in labels:\n",
    "#             f.write(l)\n",
    "#             f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_classification_report(filename):\n",
    "    with open(filename) as f:\n",
    "        s = f.read()\n",
    "    lines = [ss.strip().split('     ') for ss in s.split('\\n') if ss]\n",
    "    micro = []\n",
    "    macro = []\n",
    "    wmicro = []\n",
    "    for i, line in enumerate(lines):\n",
    "        if i % 3 == 0:\n",
    "            micro.append({'p': line[1], 'r': line[2], 'f1': line[3], 's': line[4]})\n",
    "        elif i % 3 == 1:\n",
    "            macro.append({'p': line[1], 'r': line[2], 'f1': line[3], 's': line[4]})\n",
    "        else:\n",
    "            wmicro.append({'p': line[1], 'r': line[2], 'f1': line[3], 's': line[4]})\n",
    "    return {'micro': micro, 'macro': macro, 'wmicro': wmicro}\n",
    "# read_classification_report('classification_base_ep9.txt')\n",
    "# read_classification_report('classification_kb_ohe_ep9.txt')\n",
    "# read_classification_report('classification_kb_ce_ep9.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def select(x, k=10):\n",
    "    return random.sample(x, k)\n",
    "\n",
    "def select_dict(x, k=10):\n",
    "    return sorted(x.items(), key=lambda x: -x[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'ant'), (1, 'bird'), (2, 'cat')]\n",
      "gold -> pred : support\n",
      "bird -> cat : 1\n",
      "cat -> ant : 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def show_confusion(y_true, y_pred, LABELS, min_count=0):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=LABELS)  # axis=(gold, pred)\n",
    "    print('gold -> pred : support')\n",
    "    for gold_i, a in enumerate(cm):\n",
    "        for pred_i, c in enumerate(a):\n",
    "            if gold_i != pred_i and c > min_count:\n",
    "                print(f'{LABELS[gold_i]} -> {LABELS[pred_i]} : {c}')\n",
    "\n",
    "\n",
    "y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
    "y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    "LABELS = [\"ant\", \"bird\", \"cat\"]\n",
    "print(list(enumerate(LABELS)))\n",
    "show_confusion(y_true, y_pred, LABELS, min_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def read_token_label_list(filename):\n",
    "    with open(filename) as f:\n",
    "        sentences = [[l.split('\\t') for l in s.split('\\n') if len(l.split('\\t')) == 3] for s in f.read().split('\\n\\n')]\n",
    "    print(len(sentences))\n",
    "    sentences_err = [s for s in sentences if any(pred != gold for surf, pred, gold in s)]\n",
    "    print(len(sentences_err))\n",
    "    sentences_pos = [s for s in sentences if all(pred == gold for surf, pred, gold in s)]\n",
    "    return sentences_err, sentences_pos\n",
    "\n",
    "def categorize_errors(sentences_err):\n",
    "    fns = []\n",
    "    fps_o = []\n",
    "    fps_conf = []\n",
    "\n",
    "    for i, s in enumerate(sentences_err):\n",
    "        sent = '\\n'.join( ' '.join(line) for line in s)\n",
    "    #     print(sent)\n",
    "        for surf, pred, gold in s:\n",
    "            if pred == 'O' and gold != 'O':  # gold != 'O'; FN(ひろいこぼし)\n",
    "                fns.append({'target':(surf, pred, gold), 'sentence': sent , 'sid': i})\n",
    "            elif pred != 'O':  # FP\n",
    "                if gold == 'O':\n",
    "                    fps_o.append({'target':(surf, pred, gold), 'sentence': sent , 'sid': i})\n",
    "                elif pred != gold:  # gold != 'O'\n",
    "                    fps_conf.append({'target':(surf, pred, gold), 'sentence': sent , 'sid': i})\n",
    "    print(len(sentences_err), len(fns), len(fps_o), len(fps_conf))\n",
    "    return fns, fps_o, fps_conf\n",
    "\n",
    "\n",
    "def categorize_errors_detail(fns, fps_conf, fps_o):\n",
    "\n",
    "    # FN\n",
    "    fns_counter = Counter(d['target'][2].split('-')[1] for d in fns)\n",
    "    fns_entries = {d['target'][2].split('-')[1]: [] for d in fns}\n",
    "    fns_uniq = {d['sid']: [] for d in fns}\n",
    "    for d in fns:\n",
    "        fns_uniq[ d['sid'] ].append(d['target'])\n",
    "        fns_entries[ d['target'][2].split('-')[1] ].append(d['target'])\n",
    "\n",
    "    # FP: confusion\n",
    "    fps_conf_g_counter = Counter(d['target'][2].split('-')[1] for d in fps_conf)\n",
    "    fps_conf_g_entries = {d['target'][2].split('-')[1]: [] for d in fps_conf}\n",
    "    fps_conf_p_counter = Counter(d['target'][1].split('-')[1] for d in fps_conf if d['target'][1] != 'X')\n",
    "    fps_conf_p_entries = {d['target'][1].split('-')[1]: [] for d in fps_conf if d['target'][1] != 'X'}\n",
    "    fps_conf_uniq = {d['sid']: [] for d in fps_conf}\n",
    "\n",
    "    y_gold, y_pred = [], []\n",
    "    labels = set()\n",
    "    fps_confusion = {(d['target'][2], d['target'][1]): [] for d in fps_conf}\n",
    "\n",
    "    for d in fps_conf:\n",
    "        fps_conf_uniq[ d['sid'] ].append(d['target'])\n",
    "        fps_conf_g_entries[ d['target'][2].split('-')[1] ].append(d['target'])\n",
    "        if d['target'][1] != 'X':\n",
    "            fps_conf_p_entries[ d['target'][1].split('-')[1] ].append(d['target'])\n",
    "            y_gold.append(d['target'][2])\n",
    "            y_pred.append(d['target'][1])\n",
    "            labels.add(d['target'][2])\n",
    "            labels.add(d['target'][1])\n",
    "            fps_confusion[(d['target'][2], d['target'][1])].append(d['target'])\n",
    "    labels = sorted(labels, key=lambda x: x.split('-')[1]+x[0].split('-')[0])\n",
    "\n",
    "    # FP: O as positive\n",
    "    fps_o_counter = Counter(d['target'][1] for d in fps_o)  # .split('-')[1]\n",
    "    fps_o_entries = {d['target'][1]: [] for d in fps_o}  # .split('-')[1]\n",
    "    fps_o_uniq = {d['sid']: [] for d in fps_o}\n",
    "    for d in fps_o:\n",
    "        fps_o_uniq[ d['sid'] ].append(d['target'])\n",
    "        fps_o_entries[ d['target'][1] ].append(d['target'])  # .split('-')[1]\n",
    "\n",
    "    return {\n",
    "'fn': {\n",
    "'sid2result': fns_uniq,\n",
    "'counter_gold': fns_counter,\n",
    "'entry_map_gold': fns_entries,\n",
    "},\n",
    "\n",
    "'fp_confusion': {\n",
    "'sid2result': fps_conf_uniq,\n",
    "'counter_gold': fps_conf_g_counter, 'counter_pred': fps_conf_p_counter,\n",
    "'entry_map_gold': fps_conf_g_entries, 'entry_map_pred': fps_conf_p_entries,\n",
    "'confusion_info': {'y_gold': y_gold, 'y_pred': y_pred, 'labels': labels, 'confusion_map': fps_confusion}\n",
    "},\n",
    "    \n",
    "'fp_o': {\n",
    "'sid2result': fps_o_uniq,\n",
    "'counter_pred': fps_o_counter,\n",
    "'entry_map_pred': fps_o_entries,\n",
    "}\n",
    "    }\n",
    "\n",
    "\n",
    "def error_analysis(filename):\n",
    "    sentences_err, sentences_pos = read_token_label_list(filename)\n",
    "    fns, fps_o, fps_conf = categorize_errors(sentences_err)\n",
    "    return categorize_errors_detail(fns, fps_conf, fps_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3369\n",
      "1566\n",
      "1566 2217 1578 1120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "error_detail = error_analysis('output_result_base_ep9/token_label_list_epoch9_greedy_fix.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(886,\n",
       " [('Position_Vocation', 566),\n",
       "  ('Person', 289),\n",
       "  ('Company', 161),\n",
       "  ('Corporation_Other', 143),\n",
       "  ('Government', 118),\n",
       "  ('Organization_Other', 112),\n",
       "  ('GOE_Other', 107),\n",
       "  ('City', 102),\n",
       "  ('International_Organization', 84),\n",
       "  ('Country', 57)])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 未抽出誤り; 知識依存\n",
    "fn = error_detail['fn']\n",
    "len(fn['sid2result']), select_dict(fn['counter_gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637,\n",
       " [('Position_Vocation', 257),\n",
       "  ('Person', 106),\n",
       "  ('Company', 83),\n",
       "  ('Government', 79),\n",
       "  ('City', 67),\n",
       "  ('GOE_Other', 53),\n",
       "  ('Corporation_Other', 51),\n",
       "  ('Organization_Other', 47),\n",
       "  ('Public_Institution', 31),\n",
       "  ('Sports_Organization_Other', 30)],\n",
       " [('Position_Vocation', 224),\n",
       "  ('Person', 163),\n",
       "  ('GOE_Other', 85),\n",
       "  ('Corporation_Other', 84),\n",
       "  ('Government', 84),\n",
       "  ('City', 80),\n",
       "  ('Company', 74),\n",
       "  ('Public_Institution', 37),\n",
       "  ('Country', 36),\n",
       "  ('Province', 32)])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FP混同; 文脈・語彙の問題?; KB的に対処可能\n",
    "# - 正解との部分一致: 処理が面倒（一致するところも保持）\n",
    "# - クラス誤り\n",
    "\n",
    "fp_confusion = error_detail['fp_confusion']\n",
    "len(fp_confusion['sid2result']), select_dict(fp_confusion['counter_gold']), select_dict(fp_confusion['counter_pred'])\n",
    "#x[0].split('-')[1]+x[0].split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799,\n",
       " [('B-Position_Vocation', 244),\n",
       "  ('B-Person', 213),\n",
       "  ('I-Position_Vocation', 182),\n",
       "  ('X', 177),\n",
       "  ('I-Person', 76),\n",
       "  ('B-City', 69),\n",
       "  ('I-GOE_Other', 59),\n",
       "  ('B-Country', 57),\n",
       "  ('B-Company', 56),\n",
       "  ('B-GOE_Other', 40)])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FP; 過抽出誤り; 文脈・語彙の問題?\n",
    "\n",
    "fp_o = error_detail['fp_o']\n",
    "len(fp_o['sid2result']), select_dict(fp_o['counter_pred'])\n",
    "#x[0].split('-')[1]+x[0].split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2217, 1120)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FN errors\n",
    "sum([v for k, v in fn['counter_gold'].items()]), sum(v for k, v in fp_confusion['counter_gold'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1105, 1578)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FP error\n",
    "sum([v for k, v in fp_confusion['counter_pred'].items()]), sum(v for k, v in fp_o['counter_pred'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn_crfsuite.metrics.flat_classification_report(y_true, y_pred, labels=None, **kwargs)>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "metrics.flat_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FN: 未抽出誤り\n",
    "- 知識ベースで改善する見込みがある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select(list(fn['entry_map_gold'].items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[UNK]', 'O', 'B-Person'),\n",
       " ('パウンド', 'O', 'B-Person'),\n",
       " ('ガトームソン', 'O', 'B-Person'),\n",
       " ('Ｐ', 'O', 'I-Person'),\n",
       " ('竹蔵', 'O', 'B-Person'),\n",
       " ('美紗', 'O', 'B-Person'),\n",
       " ('\\u3000', 'O', 'I-Person'),\n",
       " ('トルシエ', 'O', 'B-Person'),\n",
       " ('サザエ', 'O', 'B-Person'),\n",
       " ('文公', 'O', 'B-Person')]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select(fn['entry_map_gold']['Person'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FP混同\n",
    "## - 正解との部分一致\n",
    "## - クラス誤り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select(list(fp_confusion['entry_map_gold'].items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('武寿', 'B-City', 'B-Person'),\n",
       " ('家宝', 'B-Person', 'I-Person'),\n",
       " ('赤松', 'B-Family', 'B-Person'),\n",
       " ('シー', 'I-Position_Vocation', 'B-Person'),\n",
       " ('新太', 'B-Person', 'I-Person'),\n",
       " ('教夫', 'B-Person', 'I-Person'),\n",
       " ('深町', 'B-City', 'B-Person'),\n",
       " ('高崎', 'B-Position_Vocation', 'B-Person'),\n",
       " ('新渡戸', 'B-Station', 'B-Person'),\n",
       " ('信雄', 'B-Person', 'I-Person')]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select(fp_confusion['entry_map_gold']['Person'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold -> pred : support\n",
      "B-City -> B-GOE_Other : 11\n",
      "B-City -> B-Person : 14\n",
      "B-City -> B-Province : 13\n",
      "B-Company -> B-Corporation_Other : 7\n",
      "B-Company -> B-GOE_Other : 9\n",
      "B-Company -> B-Person : 9\n",
      "I-Company -> B-Company : 6\n",
      "I-Company -> I-GOE_Other : 9\n",
      "B-Company_Group -> B-Company : 7\n",
      "I-Corporation_Other -> B-Corporation_Other : 6\n",
      "I-Corporation_Other -> I-Government : 18\n",
      "B-Country -> B-Nationality : 6\n",
      "B-Family -> B-Person : 6\n",
      "B-GOE_Other -> B-City : 11\n",
      "I-GOE_Other -> B-GOE_Other : 8\n",
      "B-GPE_Other -> B-City : 6\n",
      "B-Government -> B-Corporation_Other : 8\n",
      "B-Government -> I-Government : 9\n",
      "B-Government -> B-Position_Vocation : 10\n",
      "I-Government -> I-Corporation_Other : 20\n",
      "I-Government -> I-Position_Vocation : 6\n",
      "I-Organization_Other -> I-Corporation_Other : 6\n",
      "I-Organization_Other -> I-Government : 7\n",
      "B-Person -> B-City : 13\n",
      "B-Person -> B-Company : 10\n",
      "B-Person -> I-Person : 9\n",
      "B-Person -> B-Position_Vocation : 7\n",
      "I-Person -> B-Person : 28\n",
      "B-Position_Vocation -> B-Person : 20\n",
      "B-Position_Vocation -> I-Person : 6\n",
      "B-Position_Vocation -> I-Position_Vocation : 45\n",
      "I-Position_Vocation -> I-Government : 6\n",
      "I-Position_Vocation -> I-International_Organization : 6\n",
      "I-Position_Vocation -> I-Organization_Other : 7\n",
      "I-Position_Vocation -> B-Position_Vocation : 93\n",
      "B-Province -> B-City : 6\n",
      "I-Public_Institution -> I-Government : 6\n",
      "I-Research_Institute -> I-Corporation_Other : 9\n"
     ]
    }
   ],
   "source": [
    "# 'confusion_info': {'y_gold': y_gold, 'y_pred': y_pred, 'labels': labels, 'confusion_map': fps_confusion}\n",
    "confusion_info = fp_confusion['confusion_info']\n",
    "y_gold, y_pred, labels = confusion_info['y_gold'], confusion_info['y_pred'], confusion_info['labels'], \n",
    "\n",
    "fps_confusion_s = {f'{k[0]} -> {k[1]}': v for k, v in confusion_info['confusion_map'].items()}\n",
    "\n",
    "show_confusion(y_gold, y_pred, labels, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('吉野', 'B-GOE_Other', 'B-Company'),\n",
       " ('吉野', 'B-GOE_Other', 'B-Company'),\n",
       " ('吉野', 'B-GOE_Other', 'B-Company'),\n",
       " ('トゥモロー', 'B-GOE_Other', 'B-Company'),\n",
       " ('ジャパレン', 'B-GOE_Other', 'B-Company'),\n",
       " ('ＳＯＧＯ', 'B-GOE_Other', 'B-Company'),\n",
       " ('大丸', 'B-GOE_Other', 'B-Company'),\n",
       " ('飯塚', 'B-GOE_Other', 'B-Company'),\n",
       " ('ラヂオ', 'B-GOE_Other', 'B-Company')]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps_confusion_s['B-Company -> B-GOE_Other']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FP; 過抽出誤り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select(list(fp_o['entry_map_pred'].items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
